# ç¬¬4ç« : ç”»åƒåˆ†é¡

## ç”»åƒåˆ†é¡ã®æ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ç”»åƒåˆ†é¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³                      â”‚
â”‚                                                         â”‚
â”‚  å…¥åŠ›ç”»åƒ        å‰å‡¦ç†         ãƒ¢ãƒ‡ãƒ«        å‡ºåŠ›        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ ğŸ–¼ï¸  â”‚  â†’  â”‚Resizeâ”‚  â†’  â”‚ CNN â”‚  â†’  â”‚ çŒ«  â”‚       â”‚
â”‚  â”‚     â”‚      â”‚Norm  â”‚      â”‚     â”‚      â”‚ 90% â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  224x224 RGB    0-1æ­£è¦åŒ–    ç‰¹å¾´æŠ½å‡º    ã‚¯ãƒ©ã‚¹ç¢ºç‡      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨

### MobileNet

```typescript
import * as tf from "@tensorflow/tfjs";
import * as mobilenet from "@tensorflow-models/mobilenet";

async function classifyImage(imageElement: HTMLImageElement) {
  // ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
  const model = await mobilenet.load({
    version: 2,
    alpha: 1.0, // ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆ0.25, 0.5, 0.75, 1.0ï¼‰
  });

  // åˆ†é¡ã‚’å®Ÿè¡Œ
  const predictions = await model.classify(imageElement, 5); // Top 5

  return predictions;
  // [
  //   { className: "tabby, tabby cat", probability: 0.85 },
  //   { className: "tiger cat", probability: 0.10 },
  //   ...
  // ]
}

// ä½¿ç”¨ä¾‹
const img = document.getElementById("myImage") as HTMLImageElement;
const results = await classifyImage(img);
console.log(results);
```

### COCO-SSDï¼ˆç‰©ä½“æ¤œå‡ºï¼‰

```typescript
import * as cocoSsd from "@tensorflow-models/coco-ssd";

interface Detection {
  bbox: [number, number, number, number]; // [x, y, width, height]
  class: string;
  score: number;
}

async function detectObjects(
  imageElement: HTMLImageElement,
): Promise<Detection[]> {
  const model = await cocoSsd.load({
    base: "mobilenet_v2", // ã¾ãŸã¯ "lite_mobilenet_v2"
  });

  const predictions = await model.detect(imageElement);

  return predictions.map((p) => ({
    bbox: p.bbox as [number, number, number, number],
    class: p.class,
    score: p.score,
  }));
}

// æ¤œå‡ºçµæœã‚’æç”»
function drawDetections(
  canvas: HTMLCanvasElement,
  image: HTMLImageElement,
  detections: Detection[],
) {
  const ctx = canvas.getContext("2d")!;
  canvas.width = image.width;
  canvas.height = image.height;

  // ç”»åƒã‚’æç”»
  ctx.drawImage(image, 0, 0);

  // æ¤œå‡ºçµæœã‚’æç”»
  detections.forEach((detection) => {
    const [x, y, width, height] = detection.bbox;

    // ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
    ctx.strokeStyle = "#00ff00";
    ctx.lineWidth = 2;
    ctx.strokeRect(x, y, width, height);

    // ãƒ©ãƒ™ãƒ«
    ctx.fillStyle = "#00ff00";
    ctx.font = "16px Arial";
    ctx.fillText(
      `${detection.class} (${(detection.score * 100).toFixed(1)}%)`,
      x,
      y - 5,
    );
  });
}
```

## ç”»åƒã®å‰å‡¦ç†

```typescript
// ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
function imageToTensor(
  image: HTMLImageElement | HTMLCanvasElement,
  targetSize: [number, number] = [224, 224],
): tf.Tensor3D {
  return tf.tidy(() => {
    // ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
    let tensor = tf.browser.fromPixels(image);

    // ãƒªã‚µã‚¤ã‚º
    const resized = tf.image.resizeBilinear(tensor, targetSize);

    // æ­£è¦åŒ–ï¼ˆ0-255 â†’ 0-1ï¼‰
    const normalized = resized.div(255.0);

    return normalized as tf.Tensor3D;
  });
}

// ãƒãƒƒãƒå‡¦ç†ç”¨
function imageToBatchTensor(
  image: HTMLImageElement,
  targetSize: [number, number] = [224, 224],
): tf.Tensor4D {
  return tf.tidy(() => {
    const tensor = imageToTensor(image, targetSize);
    return tensor.expandDims(0) as tf.Tensor4D;
  });
}

// ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
function augmentImage(tensor: tf.Tensor3D): tf.Tensor3D {
  return tf.tidy(() => {
    let augmented = tensor;

    // ãƒ©ãƒ³ãƒ€ãƒ ã«å·¦å³åè»¢
    if (Math.random() > 0.5) {
      augmented = tf.image.flipLeftRight(augmented);
    }

    // ãƒ©ãƒ³ãƒ€ãƒ ã«å›è»¢ï¼ˆ-15Â° ~ 15Â°ï¼‰
    const angle = (Math.random() - 0.5) * 30 * (Math.PI / 180);
    // TensorFlow.js ã«ã¯ç›´æ¥ã®å›è»¢ãŒãªã„ãŸã‚ã€affineå¤‰æ›ã‚’ä½¿ç”¨

    // æ˜ã‚‹ã•èª¿æ•´
    const brightness = Math.random() * 0.4 - 0.2;
    augmented = augmented.add(brightness);

    // ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
    const contrast = 0.8 + Math.random() * 0.4;
    const mean = augmented.mean();
    augmented = augmented.sub(mean).mul(contrast).add(mean);

    // ã‚¯ãƒªãƒƒãƒ—
    augmented = tf.clipByValue(augmented, 0, 1);

    return augmented as tf.Tensor3D;
  });
}
```

## CNN ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰

### åŸºæœ¬çš„ãª CNN

```typescript
function createCNNModel(
  inputShape: [number, number, number],
  numClasses: number,
): tf.LayersModel {
  const model = tf.sequential();

  // ç•³ã¿è¾¼ã¿å±¤ 1
  model.add(
    tf.layers.conv2d({
      inputShape,
      filters: 32,
      kernelSize: 3,
      activation: "relu",
      padding: "same",
    }),
  );
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));

  // ç•³ã¿è¾¼ã¿å±¤ 2
  model.add(
    tf.layers.conv2d({
      filters: 64,
      kernelSize: 3,
      activation: "relu",
      padding: "same",
    }),
  );
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));

  // ç•³ã¿è¾¼ã¿å±¤ 3
  model.add(
    tf.layers.conv2d({
      filters: 128,
      kernelSize: 3,
      activation: "relu",
      padding: "same",
    }),
  );
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));

  // å…¨çµåˆå±¤
  model.add(tf.layers.flatten());
  model.add(tf.layers.dropout({ rate: 0.5 }));
  model.add(tf.layers.dense({ units: 256, activation: "relu" }));
  model.add(tf.layers.dropout({ rate: 0.5 }));
  model.add(tf.layers.dense({ units: numClasses, activation: "softmax" }));

  model.compile({
    optimizer: tf.train.adam(0.001),
    loss: "categoricalCrossentropy",
    metrics: ["accuracy"],
  });

  return model;
}

// ä½¿ç”¨ä¾‹
const model = createCNNModel([224, 224, 3], 10);
model.summary();
```

### è»¢ç§»å­¦ç¿’

```typescript
import * as mobilenet from "@tensorflow-models/mobilenet";

async function createTransferLearningModel(numClasses: number) {
  // MobileNet ã‚’èª­ã¿è¾¼ã¿
  const mobilenetModel = await mobilenet.load({ version: 2, alpha: 1.0 });

  // ç‰¹å¾´æŠ½å‡ºç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
  const layer = mobilenetModel.model.getLayer("global_average_pooling2d_1");
  const featureModel = tf.model({
    inputs: mobilenetModel.model.inputs,
    outputs: layer.output,
  });

  // æ–°ã—ã„åˆ†é¡å±¤ã‚’è¿½åŠ 
  const model = tf.sequential();

  // MobileNet ã®å‡ºåŠ›ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹
  model.add(
    tf.layers.dense({
      inputShape: [1280], // MobileNet V2 ã®å‡ºåŠ›æ¬¡å…ƒ
      units: 128,
      activation: "relu",
    }),
  );
  model.add(tf.layers.dropout({ rate: 0.5 }));
  model.add(
    tf.layers.dense({
      units: numClasses,
      activation: "softmax",
    }),
  );

  model.compile({
    optimizer: tf.train.adam(0.0001), // ä½ã„å­¦ç¿’ç‡
    loss: "categoricalCrossentropy",
    metrics: ["accuracy"],
  });

  return { featureModel, classificationModel: model };
}

// è¨“ç·´
async function trainTransferLearning(
  featureModel: tf.LayersModel,
  classificationModel: tf.Sequential,
  images: tf.Tensor4D,
  labels: tf.Tensor2D,
) {
  // ç‰¹å¾´é‡ã‚’æŠ½å‡º
  const features = featureModel.predict(images) as tf.Tensor2D;

  // åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
  await classificationModel.fit(features, labels, {
    epochs: 50,
    validationSplit: 0.2,
    callbacks: tf.callbacks.earlyStopping({ patience: 5 }),
  });
}
```

## å®Ÿè·µ: å•†å“ç”»åƒåˆ†é¡

```typescript
// Next.js API Route ã§ã®ç”»åƒåˆ†é¡
// app/api/classify/route.ts
import * as tf from "@tensorflow/tfjs-node";
import * as mobilenet from "@tensorflow-models/mobilenet";

let model: mobilenet.MobileNet | null = null;

async function getModel() {
  if (!model) {
    // tf-node ã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦è¨­å®š
    await tf.ready();
    model = await mobilenet.load();
  }
  return model;
}

export async function POST(request: Request) {
  const formData = await request.formData();
  const file = formData.get("image") as File;

  if (!file) {
    return Response.json({ error: "No image provided" }, { status: 400 });
  }

  // ç”»åƒã‚’ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦èª­ã¿è¾¼ã¿
  const buffer = Buffer.from(await file.arrayBuffer());

  // ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
  const tensor = tf.node.decodeImage(buffer, 3);

  // åˆ†é¡
  const classifier = await getModel();
  const predictions = await classifier.classify(tensor as tf.Tensor3D);

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  tensor.dispose();

  return Response.json({
    predictions: predictions.map((p) => ({
      label: p.className,
      confidence: p.probability,
    })),
  });
}
```

## ãƒ–ãƒ©ã‚¦ã‚¶ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡

```typescript
// React ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
import { useEffect, useRef, useState } from "react";
import * as mobilenet from "@tensorflow-models/mobilenet";

interface Prediction {
  className: string;
  probability: number;
}

export function WebcamClassifier() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [model, setModel] = useState<mobilenet.MobileNet | null>(null);
  const [predictions, setPredictions] = useState<Prediction[]>([]);
  const [isClassifying, setIsClassifying] = useState(false);

  // ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
  useEffect(() => {
    mobilenet.load().then(setModel);
  }, []);

  // ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹
  useEffect(() => {
    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" },
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
    }
    startCamera();
  }, []);

  // åˆ†é¡ã‚’å®Ÿè¡Œ
  const classify = async () => {
    if (!model || !videoRef.current) return;

    setIsClassifying(true);
    const predictions = await model.classify(videoRef.current);
    setPredictions(predictions);
    setIsClassifying(false);
  };

  // å®šæœŸçš„ã«åˆ†é¡
  useEffect(() => {
    if (!model) return;

    const interval = setInterval(classify, 1000);
    return () => clearInterval(interval);
  }, [model]);

  return (
    <div className="space-y-4">
      <video ref={videoRef} autoPlay playsInline className="w-full max-w-md" />

      {predictions.length > 0 && (
        <div className="bg-gray-100 p-4 rounded">
          <h3 className="font-bold mb-2">æ¤œå‡ºçµæœ:</h3>
          {predictions.map((p, i) => (
            <div key={i} className="flex justify-between">
              <span>{p.className}</span>
              <span>{(p.probability * 100).toFixed(1)}%</span>
            </div>
          ))}
        </div>
      )}
    </div>
  );
}
```

## ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

```typescript
// ã‚«ã‚¹ã‚¿ãƒ ç”»åƒåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
async function trainCustomClassifier(
  images: ImageData[], // { data: Uint8ClampedArray, label: number }[]
  labels: string[],
) {
  const numClasses = labels.length;

  // ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
  const imageTensors = images.map((img) => {
    const tensor = tf.browser.fromPixels({
      data: img.data,
      width: 224,
      height: 224,
    });
    return tensor.div(255.0);
  });

  const xTrain = tf.stack(imageTensors);
  const yTrain = tf.oneHot(
    tf.tensor1d(
      images.map((img) => img.label),
      "int32",
    ),
    numClasses,
  );

  // ãƒ¢ãƒ‡ãƒ«ä½œæˆ
  const { featureModel, classificationModel } =
    await createTransferLearningModel(numClasses);

  // ç‰¹å¾´æŠ½å‡º
  const features = featureModel.predict(xTrain) as tf.Tensor2D;

  // è¨“ç·´
  await classificationModel.fit(features, yTrain, {
    epochs: 30,
    validationSplit: 0.2,
    callbacks: {
      onEpochEnd: (epoch, logs) => {
        console.log(`Epoch ${epoch + 1}: acc=${logs?.acc?.toFixed(3)}`);
      },
    },
  });

  // ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
  await classificationModel.save("indexeddb://custom-classifier");

  // ãƒ¡ãƒ¢ãƒªè§£æ”¾
  imageTensors.forEach((t) => t.dispose());
  xTrain.dispose();
  yTrain.dispose();
  features.dispose();

  return { featureModel, classificationModel, labels };
}
```

## ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡

```typescript
interface ClassificationMetrics {
  accuracy: number;
  precision: number[];
  recall: number[];
  f1Score: number[];
  confusionMatrix: number[][];
}

function evaluateClassifier(
  predictions: number[],
  actual: number[],
  numClasses: number,
): ClassificationMetrics {
  // æ··åŒè¡Œåˆ—ã‚’ä½œæˆ
  const confusionMatrix: number[][] = Array(numClasses)
    .fill(null)
    .map(() => Array(numClasses).fill(0));

  predictions.forEach((pred, i) => {
    confusionMatrix[actual[i]][pred]++;
  });

  // ç²¾åº¦
  const correct = predictions.filter((p, i) => p === actual[i]).length;
  const accuracy = correct / predictions.length;

  // ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç²¾åº¦ã€å†ç¾ç‡ã€F1
  const precision: number[] = [];
  const recall: number[] = [];
  const f1Score: number[] = [];

  for (let c = 0; c < numClasses; c++) {
    const tp = confusionMatrix[c][c];
    const fp = confusionMatrix.reduce(
      (sum, row, i) => (i !== c ? sum + row[c] : sum),
      0,
    );
    const fn = confusionMatrix[c].reduce(
      (sum, val, i) => (i !== c ? sum + val : sum),
      0,
    );

    const p = tp / (tp + fp) || 0;
    const r = tp / (tp + fn) || 0;
    const f1 = (2 * p * r) / (p + r) || 0;

    precision.push(p);
    recall.push(r);
    f1Score.push(f1);
  }

  return { accuracy, precision, recall, f1Score, confusionMatrix };
}
```

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ç”»åƒåˆ†é¡ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹                     â”‚
â”‚                                                         â”‚
â”‚  1. ãƒ‡ãƒ¼ã‚¿                                               â”‚
â”‚     â€¢ ã‚¯ãƒ©ã‚¹ã”ã¨ã«ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆæœ€ä½100æš/ã‚¯ãƒ©ã‚¹ï¼‰    â”‚
â”‚     â€¢ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã§å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™                         â”‚
â”‚     â€¢ ã‚¯ãƒ©ã‚¹é–“ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹                           â”‚
â”‚                                                         â”‚
â”‚  2. å‰å‡¦ç†                                               â”‚
â”‚     â€¢ ä¸€è²«ã—ãŸã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚ºï¼ˆ224x224ç­‰ï¼‰              â”‚
â”‚     â€¢ æ­£è¦åŒ–ï¼ˆ0-1 ã¾ãŸã¯ ImageNet æ¨™æº–åŒ–ï¼‰              â”‚
â”‚     â€¢ è¨“ç·´/ãƒ†ã‚¹ãƒˆã§åŒã˜å‰å‡¦ç†ã‚’é©ç”¨                     â”‚
â”‚                                                         â”‚
â”‚  3. ãƒ¢ãƒ‡ãƒ«                                               â”‚
â”‚     â€¢ å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯è»¢ç§»å­¦ç¿’ã‚’ä½¿ç”¨               â”‚
â”‚     â€¢ MobileNet ã¯è»½é‡ã§é«˜é€Ÿ                            â”‚
â”‚     â€¢ éå­¦ç¿’é˜²æ­¢ã« Dropout ã‚’ä½¿ç”¨                       â”‚
â”‚                                                         â”‚
â”‚  4. è¨“ç·´                                                 â”‚
â”‚     â€¢ æ—©æœŸåœæ­¢ã§éå­¦ç¿’ã‚’é˜²æ­¢                            â”‚
â”‚     â€¢ å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°                            â”‚
â”‚     â€¢ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡                                  â”‚
â”‚                                                         â”‚
â”‚  5. ãƒ‡ãƒ—ãƒ­ã‚¤                                             â”‚
â”‚     â€¢ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’è€ƒæ…®ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶å‘ã‘ã¯è»½é‡åŒ–ï¼‰         â”‚
â”‚     â€¢ é‡å­åŒ–ã§ã‚µã‚¤ã‚ºå‰Šæ¸›                                â”‚
â”‚     â€¢ WebGL/WASM ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ä½¿ç”¨                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

æ¬¡ç« ã§ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚
