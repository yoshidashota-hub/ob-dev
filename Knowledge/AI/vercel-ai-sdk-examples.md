# Vercel AI SDK å®Ÿè£…ä¾‹

ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®å®Œå…¨ã‚¬ã‚¤ãƒ‰ã€‚

---

## ğŸ“‹ ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
3. [åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆå®Ÿè£…](#åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆå®Ÿè£…)
4. [ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”](#ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”)
5. [ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ](#ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ)
6. [é«˜åº¦ãªä½¿ç”¨ä¾‹](#é«˜åº¦ãªä½¿ç”¨ä¾‹)
7. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## æ¦‚è¦

### Vercel AI SDK ã¨ã¯

AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç°¡å˜ã«æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼š
- **ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«å¯¾å¿œ**: OpenAIã€Anthropicã€Googleã€Mistral ãªã©
- **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§AIã®å¿œç­”ã‚’è¡¨ç¤º
- **React Hooks**: useChatã€useCompletion ã§ç°¡å˜å®Ÿè£…
- **Edge Runtime**: é«˜é€Ÿã§ä½ã‚³ã‚¹ãƒˆãªå®Ÿè¡Œç’°å¢ƒ

### ä¸»ãªæ©Ÿèƒ½

- ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆä¼šè©±å±¥æ­´ä»˜ãï¼‰
- ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
- é–¢æ•°å‘¼ã³å‡ºã—ï¼ˆFunction Callingï¼‰
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ï¼ˆç”»åƒå…¥åŠ›ï¼‰
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”

---

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# AI SDK Core
npm install ai

# Anthropic (Claude)
npm install @ai-sdk/anthropic

# OpenAI (GPT)
npm install @ai-sdk/openai

# Google (Gemini)
npm install @ai-sdk/google
```

### 2. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

**ãƒ•ã‚¡ã‚¤ãƒ«**: `.env.local`

```bash
# Anthropic (æ¨å¥¨)
ANTHROPIC_API_KEY="sk-ant-xxxx"

# ã¾ãŸã¯ OpenAI
OPENAI_API_KEY="sk-xxxx"

# ã¾ãŸã¯ Google
GOOGLE_API_KEY="xxxx"
```

### 3. API ã‚­ãƒ¼ã®å–å¾—

#### Anthropic Claude

```
1. https://console.anthropic.com/ ã«ã‚¢ã‚¯ã‚»ã‚¹
2. Settings â†’ API Keys
3. "Create Key" ã‚’ã‚¯ãƒªãƒƒã‚¯
4. ã‚­ãƒ¼ã‚’ã‚³ãƒ”ãƒ¼
```

#### OpenAI

```
1. https://platform.openai.com/api-keys ã«ã‚¢ã‚¯ã‚»ã‚¹
2. "Create new secret key" ã‚’ã‚¯ãƒªãƒƒã‚¯
3. ã‚­ãƒ¼ã‚’ã‚³ãƒ”ãƒ¼
```

---

## åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆå®Ÿè£…

### Chat API ã®ä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `app/api/chat/route.ts`

```typescript
import { anthropic } from '@ai-sdk/anthropic';
import { streamText } from 'ai';

// Edge Runtime ã§å®Ÿè¡Œï¼ˆé«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆï¼‰
export const runtime = 'edge';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: anthropic('claude-3-5-sonnet-20241022'),
    system: 'You are a helpful assistant for a Next.js 16 sandbox application.',
    messages,
  });

  return result.toDataStreamResponse();
}
```

### ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã®ä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `app/ai-chat/page.tsx`

```typescript
'use client';

import { useChat } from 'ai/react';

export default function ChatPage() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } =
    useChat();

  return (
    <div className="max-w-4xl mx-auto p-8">
      <h1 className="text-4xl font-bold mb-6">ğŸ¤– AI Chat</h1>

      <div className="bg-white rounded-lg shadow">
        {/* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºã‚¨ãƒªã‚¢ */}
        <div className="h-[500px] overflow-y-auto p-6 space-y-4">
          {messages.length === 0 && (
            <div className="text-center text-gray-500 mt-20">
              <p className="text-lg">Start a conversation!</p>
              <p className="text-sm mt-2">
                Ask me anything about Next.js, React, or web development.
              </p>
            </div>
          )}

          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${
                message.role === 'user' ? 'justify-end' : 'justify-start'
              }`}
            >
              <div
                className={`max-w-[80%] rounded-lg p-4 ${
                  message.role === 'user'
                    ? 'bg-blue-600 text-white'
                    : 'bg-gray-100 text-gray-900'
                }`}
              >
                <p className="whitespace-pre-wrap">{message.content}</p>
              </div>
            </div>
          ))}

          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-gray-100 rounded-lg p-4">
                <div className="flex space-x-2">
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" />
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce delay-100" />
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce delay-200" />
                </div>
              </div>
            </div>
          )}
        </div>

        {/* å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  */}
        <form onSubmit={handleSubmit} className="border-t p-4">
          <div className="flex space-x-4">
            <input
              value={input}
              onChange={handleInputChange}
              placeholder="Type your message..."
              className="flex-1 px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
              disabled={isLoading}
            />
            <button
              type="submit"
              disabled={isLoading || !input.trim()}
              className="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:bg-gray-300 disabled:cursor-not-allowed"
            >
              Send
            </button>
          </div>
        </form>
      </div>
    </div>
  );
}
```

---

## ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ä»•çµ„ã¿

```typescript
import { streamText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';

export async function POST(req: Request) {
  const { messages } = await req.json();

  // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’ç”Ÿæˆ
  const result = await streamText({
    model: anthropic('claude-3-5-sonnet-20241022'),
    messages,
  });

  // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
  return result.toDataStreamResponse();
}
```

### ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†

```typescript
import { streamText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: anthropic('claude-3-5-sonnet-20241022'),
    messages,
    onFinish: ({ text, usage }) => {
      // ç”Ÿæˆå®Œäº†æ™‚ã®å‡¦ç†
      console.log('Generated text:', text);
      console.log('Token usage:', usage);
    },
  });

  return result.toDataStreamResponse();
}
```

---

## ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ

### useCompletion ãƒ•ãƒƒã‚¯ã®ä½¿ç”¨

**ãƒ•ã‚¡ã‚¤ãƒ«**: `app/api/completion/route.ts`

```typescript
import { streamText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';

export const runtime = 'edge';

export async function POST(req: Request) {
  const { prompt } = await req.json();

  const result = await streamText({
    model: anthropic('claude-3-5-sonnet-20241022'),
    prompt,
  });

  return result.toDataStreamResponse();
}
```

**ãƒ•ã‚¡ã‚¤ãƒ«**: `app/text-generation/page.tsx`

```typescript
'use client';

import { useCompletion } from 'ai/react';

export default function TextGenerationPage() {
  const { completion, input, handleInputChange, handleSubmit, isLoading } =
    useCompletion();

  return (
    <div className="max-w-4xl mx-auto p-8">
      <h1 className="text-4xl font-bold mb-6">âœï¸ Text Generation</h1>

      <div className="bg-white rounded-lg shadow p-6">
        <form onSubmit={handleSubmit} className="mb-6">
          <label className="block text-sm font-medium text-gray-700 mb-2">
            Prompt
          </label>
          <textarea
            value={input}
            onChange={handleInputChange}
            placeholder="Enter your prompt..."
            rows={4}
            className="w-full px-3 py-2 border rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
            disabled={isLoading}
          />
          <button
            type="submit"
            disabled={isLoading || !input.trim()}
            className="mt-3 px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:bg-gray-300"
          >
            {isLoading ? 'Generating...' : 'Generate'}
          </button>
        </form>

        {completion && (
          <div className="bg-gray-50 rounded-lg p-4">
            <h2 className="text-lg font-semibold mb-2">Result:</h2>
            <p className="whitespace-pre-wrap">{completion}</p>
          </div>
        )}
      </div>
    </div>
  );
}
```

---

## é«˜åº¦ãªä½¿ç”¨ä¾‹

### 1. ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

```typescript
import { streamText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: anthropic('claude-3-5-sonnet-20241022'),
    system: `You are a professional Japanese translator.
      - Translate English to natural Japanese
      - Keep technical terms in English when appropriate
      - Maintain the tone and style of the original text`,
    messages,
  });

  return result.toDataStreamResponse();
}
```

### 2. æ¸©åº¦ã¨ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã®è¨­å®š

```typescript
const result = await streamText({
  model: anthropic('claude-3-5-sonnet-20241022'),
  messages,
  temperature: 0.7, // 0-1: ä½ã„ã»ã©æ±ºå®šçš„ã€é«˜ã„ã»ã©å‰µé€ çš„
  maxTokens: 1000, // æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
  topP: 0.9, // Nucleus sampling
});
```

### 3. è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä½¿ã„åˆ†ã‘

```typescript
import { anthropic } from '@ai-sdk/anthropic';
import { openai } from '@ai-sdk/openai';

export async function POST(req: Request) {
  const { messages, model } = await req.json();

  let selectedModel;
  switch (model) {
    case 'claude':
      selectedModel = anthropic('claude-3-5-sonnet-20241022');
      break;
    case 'gpt-4':
      selectedModel = openai('gpt-4-turbo');
      break;
    case 'gpt-3.5':
      selectedModel = openai('gpt-3.5-turbo');
      break;
    default:
      selectedModel = anthropic('claude-3-5-sonnet-20241022');
  }

  const result = await streamText({
    model: selectedModel,
    messages,
  });

  return result.toDataStreamResponse();
}
```

### 4. Function Callingï¼ˆãƒ„ãƒ¼ãƒ«ä½¿ç”¨ï¼‰

```typescript
import { streamText, tool } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';
import { z } from 'zod';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: anthropic('claude-3-5-sonnet-20241022'),
    messages,
    tools: {
      getWeather: tool({
        description: 'Get the weather for a location',
        parameters: z.object({
          location: z.string().describe('The location to get weather for'),
        }),
        execute: async ({ location }) => {
          // å®Ÿéš›ã®å¤©æ°—APIã‚’å‘¼ã³å‡ºã™
          const weather = await fetchWeather(location);
          return weather;
        },
      }),
      searchDatabase: tool({
        description: 'Search the database for information',
        parameters: z.object({
          query: z.string().describe('The search query'),
        }),
        execute: async ({ query }) => {
          const results = await searchDB(query);
          return results;
        },
      }),
    },
  });

  return result.toDataStreamResponse();
}
```

### 5. ä¼šè©±å±¥æ­´ã®ä¿å­˜

```typescript
'use client';

import { useChat } from 'ai/react';
import { useEffect } from 'react';

export default function ChatWithHistory() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    id: 'persistent-chat', // ãƒãƒ£ãƒƒãƒˆ ID
    onFinish: (message) => {
      // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
      saveChatHistory(message);
    },
  });

  // ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
  useEffect(() => {
    localStorage.setItem('chat-messages', JSON.stringify(messages));
  }, [messages]);

  return (
    <div>
      {/* ãƒãƒ£ãƒƒãƒˆ UI */}
    </div>
  );
}
```

### 6. RAGï¼ˆRetrieval Augmented Generationï¼‰

```typescript
import { streamText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';
import { searchDocuments } from '@/lib/vector-search';

export async function POST(req: Request) {
  const { messages } = await req.json();
  const lastMessage = messages[messages.length - 1].content;

  // ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
  const relevantDocs = await searchDocuments(lastMessage);

  const context = relevantDocs.map(doc => doc.content).join('\n\n');

  const result = await streamText({
    model: anthropic('claude-3-5-sonnet-20241022'),
    system: `You are a helpful assistant. Use the following context to answer questions:

Context:
${context}

If the answer is not in the context, say "I don't have enough information to answer that."`,
    messages,
  });

  return result.toDataStreamResponse();
}
```

### 7. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ï¼ˆç”»åƒå…¥åŠ›ï¼‰

```typescript
import { streamText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: anthropic('claude-3-5-sonnet-20241022'),
    messages: [
      {
        role: 'user',
        content: [
          {
            type: 'text',
            text: 'What is in this image?',
          },
          {
            type: 'image',
            image: 'https://example.com/image.jpg',
          },
        ],
      },
    ],
  });

  return result.toDataStreamResponse();
}
```

### 8. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆã®ç›£è¦–

```typescript
'use client';

import { useChat } from 'ai/react';

export default function ChatWithEvents() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    onResponse: (response) => {
      console.log('Response started:', response);
    },
    onFinish: (message) => {
      console.log('Response finished:', message);
    },
    onError: (error) => {
      console.error('Error:', error);
    },
  });

  return (
    <div>
      {/* ãƒãƒ£ãƒƒãƒˆ UI */}
    </div>
  );
}
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼: "API key not found"

```bash
# ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèª
echo $ANTHROPIC_API_KEY

# .env.local ã«è¿½åŠ 
ANTHROPIC_API_KEY="sk-ant-xxxx"

# ã‚µãƒ¼ãƒãƒ¼ã‚’å†èµ·å‹•
npm run dev
```

### ã‚¨ãƒ©ãƒ¼: "Rate limit exceeded"

```typescript
// ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
import { streamText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';

export async function POST(req: Request) {
  const { messages } = await req.json();

  try {
    const result = await streamText({
      model: anthropic('claude-3-5-sonnet-20241022'),
      messages,
    });

    return result.toDataStreamResponse();
  } catch (error: any) {
    if (error.message?.includes('rate limit')) {
      return new Response(
        JSON.stringify({ error: 'Rate limit exceeded. Please try again later.' }),
        { status: 429 }
      );
    }
    throw error;
  }
}
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒå‹•ä½œã—ãªã„

```typescript
// Edge Runtime ã‚’ä½¿ç”¨
export const runtime = 'edge';

// ã¾ãŸã¯ Node.js Runtime ã§å‹•çš„ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
export const dynamic = 'force-dynamic';
```

### ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ

```typescript
// Claude 3.5 Sonnet (æ¨å¥¨: ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„)
anthropic('claude-3-5-sonnet-20241022')

// Claude 3 Opus (é«˜æ€§èƒ½ã ãŒã‚³ã‚¹ãƒˆãŒé«˜ã„)
anthropic('claude-3-opus-20240229')

// Claude 3 Haiku (é«˜é€Ÿã§å®‰ä¾¡)
anthropic('claude-3-haiku-20240307')

// OpenAI GPT-4 Turbo
openai('gpt-4-turbo')

// OpenAI GPT-3.5 Turbo (å®‰ä¾¡)
openai('gpt-3.5-turbo')
```

---

## ã¾ã¨ã‚

### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] AI SDK ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- [ ] API ã‚­ãƒ¼ã‚’å–å¾—ã—ã¦è¨­å®š
- [ ] Chat API ã‚’å®Ÿè£…
- [ ] useChat ãƒ•ãƒƒã‚¯ã§ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚’ä½œæˆ
- [ ] ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’ç¢ºèª
- [ ] ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè£…
- [ ] Vercel ã«ãƒ‡ãƒ—ãƒ­ã‚¤

### ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

- âœ… Edge Runtime ã§å®Ÿè¡Œï¼ˆé«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆï¼‰
- âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’å‘ä¸Š
- âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æŒ¯ã‚‹èˆã„ã‚’åˆ¶å¾¡
- âœ… Rate Limiting ã‚’å®Ÿè£…
- âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’é©åˆ‡ã«å®Ÿè£…
- âœ… ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’ç›£è¦–

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

- Edge Config ã§ Feature Flags ã‚’å®Ÿè£…
- Vercel Postgres ã§ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜
- Function Calling ã§ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚’å®Ÿè£…

---

**æœ€çµ‚æ›´æ–°**: 2025å¹´11æœˆ
**é›£æ˜“åº¦**: â˜…â˜…â˜…â˜…â˜†
**æ‰€è¦æ™‚é–“**: 3-4æ™‚é–“
